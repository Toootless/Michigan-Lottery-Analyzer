# Michigan Lottery Analyzer v2.3 - Technical Documentation

## üèóÔ∏è System Architecture

### Overview
The Michigan Lottery Analyzer is a full-stack Streamlit application with integrated AI learning, multi-source data management, and seamless purchase integration. Built using Python 3.11+ with modern web technologies.

### Core Components

#### 1. Application Layer (`MichiganLotteryAnalyzer.py`)
- **Size**: 5,258 lines of code
- **Framework**: Streamlit 1.25+
- **Architecture**: Single-page application with 8-tab navigation
- **Key Functions**: 50+ functions for analysis, visualization, and purchase integration

#### 2. Data Layer (`fixed_scraper.py` & CSV system)
- **Primary**: CSV files with historical lottery data
- **Secondary**: Real-time web scraping from Michigan Lottery
- **Tertiary**: Sample data generation for missing dates
- **Storage**: Local file system with automatic backup

#### 3. AI Layer (Integrated ML system)
- **Learning Algorithm**: Dynamic weight adjustment based on prediction accuracy
- **Pattern Recognition**: Advanced sequence and relationship analysis
- **Performance Tracking**: Historical suggestion verification system
- **Continuous Improvement**: Self-optimizing recommendation engine

### Technology Stack

#### Core Dependencies:
```python
streamlit>=1.25.0          # Web application framework
pandas>=1.5.0              # Data manipulation and analysis
numpy>=1.21.0              # Numerical computing
requests>=2.28.0           # HTTP library for web scraping
beautifulsoup4>=4.11.0     # HTML parsing for web scraping
matplotlib>=3.5.0          # Static plotting
seaborn>=0.11.0            # Statistical visualization
plotly>=5.10.0             # Interactive plotting
datetime                   # Date/time handling
json                       # JSON data processing
os, sys, pathlib          # System operations
random                     # Random number generation
```

#### Optional Dependencies:
```python
pytesseract>=0.3.10        # OCR for PDF processing
pillow>=9.2.0              # Image processing
pdf2image>=1.16.0          # PDF to image conversion
pymupdf>=1.20.0            # Advanced PDF processing
transformers>=4.21.0       # Hugging Face transformers
torch>=1.12.0              # PyTorch for deep learning
```

## üìä Data Architecture

### Data Sources Hierarchy

#### 1. Primary Data (CSV Files)
**Location**: `data/final_integrated_data/`
**Priority**: Highest (fastest, most reliable)

```
‚îú‚îÄ‚îÄ Powerball_Complete.csv         # 198 results
‚îú‚îÄ‚îÄ Mega_Millions_Complete.csv     # 143 results  
‚îú‚îÄ‚îÄ Fantasy_5_Complete.csv         # Complete historical data
‚îú‚îÄ‚îÄ Daily_3_Evening_Complete.csv   # 365+ results
‚îú‚îÄ‚îÄ Daily_3_Midday_Complete.csv    # 365+ results
‚îú‚îÄ‚îÄ Daily_4_Evening_Complete.csv   # 365+ results
‚îú‚îÄ‚îÄ Daily_4_Midday_Complete.csv    # 365+ results
‚îú‚îÄ‚îÄ Lucky_for_Life_Complete.csv    # Complete historical data
‚îî‚îÄ‚îÄ Lotto_47_Complete.csv          # Complete historical data
```

**Data Format**:
```python
# CSV Structure
columns = ['Date', 'Numbers', 'Bonus', 'Jackpot', 'Next_Jackpot']
date_format = 'YYYY-MM-DD'
numbers_format = 'space-separated integers'
```

#### 2. Secondary Data (Web Scraping)
**Source**: Michigan Lottery Official Website
**Priority**: Medium (real-time, network dependent)
**Usage**: Fallback when CSV data unavailable

**Scraping Targets**:
```python
MICHIGAN_LOTTERY_URLS = {
    'Fantasy 5': 'https://www.michiganlottery.com/games/draw-games/fantasy-5',
    'Daily 4': 'https://www.michiganlottery.com/games/draw-games/daily-4',
    'Daily 3': 'https://www.michiganlottery.com/games/draw-games/daily-3',
    'Powerball': 'https://www.michiganlottery.com/games/draw-games/powerball',
    'Mega Millions': 'https://www.michiganlottery.com/games/draw-games/mega-millions'
}
```

#### 3. Tertiary Data (Sample Generation)
**Purpose**: Placeholder data for missing dates
**Priority**: Lowest (emergency fallback only)
**Method**: Statistical sampling from historical patterns

### Data Processing Pipeline

#### 1. Data Loading (`get_lottery_data()`)
```python
def get_lottery_data(game_name, days=30):
    """
    Multi-source data loading with priority hierarchy
    1. Try CSV files first (fastest)
    2. Fall back to web scraping
    3. Generate sample data if needed
    """
    # Priority 1: CSV Data
    csv_data = load_from_csv(game_name, days)
    if csv_data and len(csv_data) >= min_required:
        return csv_data
    
    # Priority 2: Web Scraping
    web_data = scrape_recent_data(game_name)
    if web_data:
        return combine_data(csv_data, web_data)
    
    # Priority 3: Sample Data
    return generate_sample_data(game_name, days)
```

#### 2. Data Validation
```python
def validate_lottery_data(data, game_name):
    """
    Comprehensive data validation
    - Date format verification
    - Number range validation
    - Completeness checking
    - Duplicate detection
    """
    validators = {
        'date_format': validate_date_format,
        'number_ranges': validate_number_ranges,
        'completeness': check_data_completeness,
        'duplicates': detect_duplicates
    }
    
    for validator_name, validator_func in validators.items():
        if not validator_func(data, game_name):
            raise DataValidationError(f"Failed {validator_name} validation")
    
    return True
```

## ü§ñ AI & Machine Learning System

### Learning Algorithm Architecture

#### 1. Prediction Storage System
```python
class PredictionTracker:
    def __init__(self):
        self.predictions = {}
        self.results = {}
        self.performance_weights = {}
    
    def store_prediction(self, game, suggestions, analysis):
        """Store prediction with timestamp and metadata"""
        prediction_id = generate_prediction_id()
        self.predictions[prediction_id] = {
            'timestamp': datetime.now(),
            'game': game,
            'suggestions': suggestions,
            'analysis_metadata': analysis,
            'verified': False
        }
        return prediction_id
    
    def verify_prediction(self, prediction_id, actual_results):
        """Compare prediction against actual draw results"""
        prediction = self.predictions[prediction_id]
        accuracy = calculate_accuracy(prediction['suggestions'], actual_results)
        self.update_performance_weights(prediction, accuracy)
        return accuracy
```

#### 2. Dynamic Weight Adjustment
```python
def update_performance_weights(self, strategy_name, accuracy):
    """
    Dynamically adjust strategy weights based on performance
    - High accuracy: Increase weight (max 2.0)
    - Low accuracy: Decrease weight (min 0.5)
    - Exponential smoothing for stability
    """
    current_weight = self.performance_weights.get(strategy_name, 1.0)
    
    # Calculate new weight based on accuracy
    if accuracy > 0.7:  # High accuracy
        new_weight = min(current_weight * 1.1, 2.0)
    elif accuracy < 0.3:  # Low accuracy
        new_weight = max(current_weight * 0.9, 0.5)
    else:  # Medium accuracy
        new_weight = current_weight  # No change
    
    # Apply exponential smoothing
    alpha = 0.3  # Smoothing factor
    self.performance_weights[strategy_name] = (
        alpha * new_weight + (1 - alpha) * current_weight
    )
```

### Statistical Analysis Algorithms

#### 1. Frequency Analysis
```python
def analyze_frequency(results):
    """
    Advanced frequency analysis with statistical significance
    """
    analysis = {
        'hot_numbers': [],
        'cold_numbers': [],
        'medium_numbers': [],
        'frequency_distribution': {},
        'statistical_significance': {}
    }
    
    # Calculate frequency for each number
    frequency_map = calculate_frequency_distribution(results)
    
    # Determine statistical significance using chi-square test
    expected_frequency = len(results) / number_range
    chi_square_stats = []
    
    for number, frequency in frequency_map.items():
        chi_square = ((frequency - expected_frequency) ** 2) / expected_frequency
        chi_square_stats.append((number, frequency, chi_square))
    
    # Classify numbers based on frequency and significance
    sorted_stats = sorted(chi_square_stats, key=lambda x: x[1], reverse=True)
    
    total_numbers = len(sorted_stats)
    hot_threshold = int(total_numbers * 0.3)  # Top 30%
    cold_threshold = int(total_numbers * 0.7)  # Bottom 30%
    
    analysis['hot_numbers'] = [item[0] for item in sorted_stats[:hot_threshold]]
    analysis['cold_numbers'] = [item[0] for item in sorted_stats[cold_threshold:]]
    analysis['medium_numbers'] = [item[0] for item in sorted_stats[hot_threshold:cold_threshold]]
    
    return analysis
```

#### 2. Pattern Recognition
```python
def analyze_deep_patterns(results, game_name):
    """
    Advanced pattern analysis including:
    - Sequence detection
    - Repeat patterns
    - Positional analysis
    - Temporal patterns
    """
    patterns = {
        'sequences': find_sequential_patterns(results),
        'repeats': find_repeat_patterns(results),
        'positions': analyze_positional_patterns(results, game_name),
        'temporal': analyze_temporal_patterns(results)
    }
    
    return patterns

def find_sequential_patterns(results):
    """Detect consecutive number sequences"""
    sequences = []
    for result in results:
        numbers = extract_numbers(result)
        for i in range(len(numbers) - 1):
            if numbers[i+1] == numbers[i] + 1:
                sequences.append((numbers[i], numbers[i+1]))
    
    # Count sequence frequency
    sequence_frequency = {}
    for seq in sequences:
        sequence_frequency[seq] = sequence_frequency.get(seq, 0) + 1
    
    return sequence_frequency
```

## üé´ Purchase Integration System

### Architecture Overview
The purchase integration system provides seamless transition from number analysis to ticket purchasing, with different handling for online-purchasable games versus retailer-only games.

#### 1. Game Classification System
```python
class GameClassifier:
    """Classifies games by purchase availability"""
    
    ONLINE_PURCHASE_GAMES = {
        'Powerball': 'https://www.michiganlottery.com/games/powerball',
        'Mega Millions': 'https://www.michiganlottery.com/games/mega-millions',
        'Fantasy 5': 'https://www.michiganlottery.com/games/fantasy-5',
        'Lucky for Life': 'https://www.michiganlottery.com/games/lucky-for-life',
        'Lotto 47': 'https://www.michiganlottery.com/games/classic-lotto-47'
    }
    
    RETAILER_ONLY_GAMES = [
        'Daily 3', 'Daily 4', 
        'Daily 3 Midday', 'Daily 3 Evening',
        'Daily 4 Midday', 'Daily 4 Evening'
    ]
    
    @classmethod
    def can_purchase_online(cls, game_name):
        """Check if game can be purchased online"""
        return game_name in cls.ONLINE_PURCHASE_GAMES
    
    @classmethod
    def get_purchase_url(cls, game_name):
        """Get purchase URL for online games"""
        return cls.ONLINE_PURCHASE_GAMES.get(game_name)
    
    @classmethod
    def is_retailer_only(cls, game_name):
        """Check if game requires retailer purchase"""
        return game_name in cls.RETAILER_ONLY_GAMES
```

#### 2. Purchase Interface Implementation
```python
def render_purchase_interface(selected_game):
    """
    Render appropriate purchase interface based on game type
    """
    st.markdown("---")
    st.markdown("**üé´ Ready to Play?**")
    
    if GameClassifier.can_purchase_online(selected_game):
        render_online_purchase_button(selected_game)
    elif GameClassifier.is_retailer_only(selected_game):
        render_retailer_information(selected_game)
    else:
        render_generic_purchase_info(selected_game)

def render_online_purchase_button(game_name):
    """Render online purchase button with styled HTML"""
    purchase_url = GameClassifier.get_purchase_url(game_name)
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown(f"**Purchase tickets for {game_name} using your suggested numbers**")
        st.markdown("*Visit the official Michigan Lottery website to buy tickets online*")
    
    with col2:
        # Styled HTML button that opens in new tab
        button_html = f'''
        <a href="{purchase_url}" target="_blank" style="
            display: inline-block;
            padding: 0.5rem 1rem;
            background-color: #ff4b4b;
            color: white;
            text-decoration: none;
            border-radius: 0.5rem;
            text-align: center;
            font-weight: bold;
            border: none;
            cursor: pointer;
            transition: background-color 0.3s;
        " onmouseover="this.style.backgroundColor='#ff3333'"
           onmouseout="this.style.backgroundColor='#ff4b4b'">
            üé´ Buy {game_name} Tickets
        </a>
        '''
        st.markdown(button_html, unsafe_allow_html=True)

def render_retailer_information(game_name):
    """Render retailer-only information for Daily games"""
    st.info(f"üè™ **{game_name} tickets can only be purchased at authorized Michigan Lottery retailers.**")
    st.markdown("üìç **Find a retailer near you:** Visit [michiganlottery.com/retailers](https://www.michiganlottery.com/retailers) to locate authorized lottery retailers in your area.")
```

### Security & Privacy Considerations

#### 1. Data Protection
- **No Personal Data Collection**: Application collects zero personal information
- **Local Processing**: All analysis performed locally on user's machine
- **No User Tracking**: No analytics or behavior monitoring
- **Secure Connections**: All external connections use HTTPS

#### 2. External Link Safety
```python
def validate_purchase_url(url):
    """Validate purchase URLs for security"""
    allowed_domains = [
        'michiganlottery.com',
        'www.michiganlottery.com'
    ]
    
    parsed_url = urlparse(url)
    if parsed_url.netloc not in allowed_domains:
        raise SecurityError(f"Unsafe domain: {parsed_url.netloc}")
    
    if parsed_url.scheme != 'https':
        raise SecurityError("Non-HTTPS URL not allowed")
    
    return True
```

## üåê Web Scraping System

### Architecture
Robust web scraping system with error handling, rate limiting, and fallback mechanisms.

#### 1. Michigan Lottery Scraper
```python
class MichiganLotteryScraper:
    """Official Michigan Lottery website scraper"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.rate_limiter = RateLimiter(calls=10, period=60)  # 10 calls per minute
    
    def scrape_game_results(self, game_name):
        """Scrape results for specific game with error handling"""
        try:
            with self.rate_limiter:
                url = self.get_game_url(game_name)
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                results = self.parse_results(soup, game_name)
                
                return self.validate_results(results, game_name)
                
        except requests.RequestException as e:
            logger.error(f"Network error scraping {game_name}: {e}")
            return None
        except Exception as e:
            logger.error(f"Parsing error for {game_name}: {e}")
            return None
    
    def parse_results(self, soup, game_name):
        """Parse HTML to extract lottery results"""
        parsers = {
            'Powerball': self.parse_powerball,
            'Mega Millions': self.parse_mega_millions,
            'Fantasy 5': self.parse_fantasy_5,
            'Daily 3': self.parse_daily_3,
            'Daily 4': self.parse_daily_4
        }
        
        parser = parsers.get(game_name)
        if not parser:
            raise ValueError(f"No parser available for {game_name}")
        
        return parser(soup)
```

#### 2. Error Handling & Fallbacks
```python
def robust_data_fetch(game_name, days=30):
    """
    Robust data fetching with multiple fallback levels
    """
    try:
        # Level 1: CSV Data (fastest, most reliable)
        csv_data = fetch_from_csv(game_name, days)
        if csv_data and len(csv_data) >= minimum_required(days):
            logger.info(f"‚úÖ Using {len(csv_data)} results from CSV for {game_name}")
            return csv_data
    except Exception as e:
        logger.warning(f"CSV fetch failed for {game_name}: {e}")
    
    try:
        # Level 2: Web Scraping (real-time, network dependent)
        web_data = scrape_lottery_results(game_name)
        if web_data and len(web_data) > 0:
            logger.info(f"‚úÖ Using {len(web_data)} results from web scraping for {game_name}")
            return web_data
    except Exception as e:
        logger.warning(f"Web scraping failed for {game_name}: {e}")
    
    try:
        # Level 3: Sample Data (emergency fallback)
        sample_data = generate_sample_data(game_name, days)
        logger.warning(f"‚ö†Ô∏è Using sample data for {game_name} (no real data available)")
        return sample_data
    except Exception as e:
        logger.error(f"Sample data generation failed for {game_name}: {e}")
        raise DataUnavailableError(f"No data source available for {game_name}")
```

## üé® User Interface Architecture

### Streamlit Application Structure

#### 1. Main Application Layout
```python
def main():
    """Main application entry point"""
    # Page configuration
    st.set_page_config(
        page_title="Michigan Lottery Analyzer v2.3",
        page_icon="üé≤",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize session state
    initialize_session_state()
    
    # Sidebar controls
    render_sidebar()
    
    # Main content area with tabs
    render_main_content()
    
    # Footer
    render_footer()

def render_main_content():
    """Render main 8-tab interface"""
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "üè† Home",
        "üìä Statistical Analysis", 
        "üéØ Smart Number Suggestions",
        "ü§ñ Learning Dashboard",
        "üìà Data Visualization",
        "üìã Historical Analysis",
        "üé≤ Quick Play",
        "üåê Michigan Lottery Web"
    ])
    
    with tab1:
        render_home_tab()
    with tab2:
        render_analysis_tab()
    with tab3:
        render_suggestions_tab()  # Contains purchase integration
    # ... additional tabs
```

#### 2. State Management
```python
def initialize_session_state():
    """Initialize Streamlit session state variables"""
    default_state = {
        'selected_game': 'Powerball',
        'analysis_period': 90,
        'prediction_history': {},
        'performance_weights': {},
        'user_preferences': {
            'theme': 'default',
            'charts_style': 'plotly',
            'download_format': 'txt'
        }
    }
    
    for key, default_value in default_state.items():
        if key not in st.session_state:
            st.session_state[key] = default_value
```

### Responsive Design Principles

#### 1. Column Layouts
```python
def create_responsive_layout():
    """Create responsive column layouts for different screen sizes"""
    # Mobile: Single column
    # Tablet: 2 columns
    # Desktop: 3-4 columns
    
    if is_mobile():
        col1 = st.container()
        return [col1]
    elif is_tablet():
        col1, col2 = st.columns(2)
        return [col1, col2]
    else:  # Desktop
        col1, col2, col3 = st.columns([2, 2, 1])
        return [col1, col2, col3]
```

#### 2. Interactive Components
```python
def render_interactive_chart(data, chart_type='bar'):
    """Render interactive charts with user controls"""
    # Chart type selector
    chart_options = ['bar', 'line', 'scatter', 'heatmap']
    selected_type = st.selectbox("Chart Type", chart_options, index=0)
    
    # Chart configuration
    config = {
        'displayModeBar': True,
        'displaylogo': False,
        'modeBarButtonsToRemove': ['pan2d', 'lasso2d']
    }
    
    # Render chart based on type
    if selected_type == 'bar':
        fig = create_bar_chart(data)
    elif selected_type == 'line':
        fig = create_line_chart(data)
    # ... additional chart types
    
    st.plotly_chart(fig, use_container_width=True, config=config)
```

## üöÄ Performance Optimization

### Caching Strategy

#### 1. Data Caching
```python
@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_lottery_data_cached(game_name, days):
    """Cached data loading to improve performance"""
    return load_lottery_data(game_name, days)

@st.cache_data(ttl=1800)  # Cache for 30 minutes
def analyze_frequency_cached(results):
    """Cached frequency analysis"""
    return analyze_frequency(results)

@st.cache_resource
def initialize_ai_model():
    """Cache AI model initialization"""
    return AILearningSystem()
```

#### 2. Memory Management
```python
def optimize_memory_usage():
    """Optimize memory usage for large datasets"""
    # Use pandas categorical data types for repeated strings
    # Implement data chunking for large files
    # Clear unused variables from memory
    
    # Example: Convert string columns to categorical
    for col in ['game_name', 'draw_type']:
        if col in df.columns:
            df[col] = df[col].astype('category')
    
    # Implement garbage collection
    import gc
    gc.collect()
```

### Scalability Considerations

#### 1. Database Migration Path
```python
class DatabaseMigrator:
    """Future database migration for improved scalability"""
    
    def migrate_csv_to_sqlite(self):
        """Migrate CSV files to SQLite database"""
        # Implementation for future database migration
        pass
    
    def create_indexes(self):
        """Create database indexes for improved query performance"""
        # Implementation for database indexing
        pass
```

#### 2. API Integration
```python
class APIClient:
    """Future API client for external lottery data services"""
    
    def __init__(self, api_key=None):
        self.api_key = api_key
        self.base_url = "https://api.lottery-data.com/v1/"
    
    async def fetch_results(self, game_name, date_range):
        """Asynchronous API data fetching"""
        # Implementation for future API integration
        pass
```

## üß™ Testing Framework

### Unit Testing
```python
import unittest
from unittest.mock import patch, MagicMock

class TestLotteryAnalyzer(unittest.TestCase):
    """Unit tests for lottery analyzer functions"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.sample_data = generate_test_data()
        self.analyzer = LotteryAnalyzer()
    
    def test_frequency_analysis(self):
        """Test frequency analysis accuracy"""
        results = self.analyzer.analyze_frequency(self.sample_data)
        self.assertIn('hot_numbers', results)
        self.assertIn('cold_numbers', results)
        self.assertTrue(len(results['hot_numbers']) > 0)
    
    def test_purchase_url_generation(self):
        """Test purchase URL generation"""
        url = GameClassifier.get_purchase_url('Powerball')
        self.assertEqual(url, 'https://www.michiganlottery.com/games/powerball')
    
    @patch('requests.get')
    def test_web_scraping(self, mock_get):
        """Test web scraping with mocked responses"""
        mock_response = MagicMock()
        mock_response.content = '<html>test content</html>'
        mock_get.return_value = mock_response
        
        scraper = MichiganLotteryScraper()
        results = scraper.scrape_game_results('Powerball')
        # Assert results are properly parsed
```

### Integration Testing
```python
class TestIntegration(unittest.TestCase):
    """Integration tests for complete workflows"""
    
    def test_full_analysis_workflow(self):
        """Test complete analysis from data loading to suggestions"""
        # Load data
        data = get_lottery_data('Powerball', 30)
        self.assertTrue(len(data) > 0)
        
        # Analyze data
        analysis = analyze_frequency(data)
        self.assertIsInstance(analysis, dict)
        
        # Generate suggestions
        suggestions = generate_number_suggestions(analysis, 'Powerball')
        self.assertTrue(len(suggestions) > 0)
    
    def test_purchase_integration(self):
        """Test purchase integration workflow"""
        # Test online purchase games
        self.assertTrue(GameClassifier.can_purchase_online('Powerball'))
        
        # Test retailer-only games
        self.assertTrue(GameClassifier.is_retailer_only('Daily 3'))
```

## üìà Monitoring & Analytics

### Performance Monitoring
```python
class PerformanceMonitor:
    """Monitor application performance metrics"""
    
    def __init__(self):
        self.metrics = {
            'load_times': [],
            'memory_usage': [],
            'error_counts': {},
            'user_interactions': []
        }
    
    def track_load_time(self, operation, duration):
        """Track operation load times"""
        self.metrics['load_times'].append({
            'operation': operation,
            'duration': duration,
            'timestamp': datetime.now()
        })
    
    def track_memory_usage(self):
        """Track memory usage"""
        import psutil
        memory_percent = psutil.virtual_memory().percent
        self.metrics['memory_usage'].append({
            'memory_percent': memory_percent,
            'timestamp': datetime.now()
        })
    
    def generate_performance_report(self):
        """Generate performance analysis report"""
        report = {
            'avg_load_time': self.calculate_average_load_time(),
            'peak_memory_usage': max(self.metrics['memory_usage']),
            'error_summary': self.summarize_errors(),
            'recommendations': self.generate_recommendations()
        }
        return report
```

### Error Logging
```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logging():
    """Configure comprehensive logging system"""
    # Create logger
    logger = logging.getLogger('lottery_analyzer')
    logger.setLevel(logging.INFO)
    
    # Create file handler with rotation
    file_handler = RotatingFileHandler(
        'logs/lottery_analyzer.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    
    # Create console handler
    console_handler = logging.StreamHandler()
    
    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Add formatter to handlers
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # Add handlers to logger
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger
```

## üîê Security Considerations

### Input Validation
```python
def validate_user_input(game_name, analysis_period):
    """Validate user input parameters"""
    # Validate game name
    allowed_games = list(LOTTERY_GAMES.keys())
    if game_name not in allowed_games:
        raise ValueError(f"Invalid game name: {game_name}")
    
    # Validate analysis period
    if not isinstance(analysis_period, int) or analysis_period < 1 or analysis_period > 365:
        raise ValueError("Analysis period must be between 1 and 365 days")
    
    return True
```

### SQL Injection Prevention
```python
def safe_database_query(query_params):
    """Use parameterized queries to prevent SQL injection"""
    # Future database implementation with proper parameterization
    safe_query = "SELECT * FROM lottery_results WHERE game_name = ? AND date >= ?"
    # Use parameterized queries, never string concatenation
    return execute_query(safe_query, query_params)
```

---

**Technical Documentation Summary:**
- **Architecture**: Multi-layered system with data, application, and AI layers
- **Performance**: Optimized caching and memory management
- **Security**: Input validation and secure external connections
- **Scalability**: Designed for future database and API integration
- **Testing**: Comprehensive unit and integration testing framework
- **Monitoring**: Performance tracking and error logging systems

*Michigan Lottery Analyzer v2.3 - Technical Documentation*  
*Last Updated: October 30, 2025*